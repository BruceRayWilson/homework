{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8083064",
   "metadata": {},
   "source": [
    "\n",
    "# Project Overview\n",
    "This Jupyter Notebook combines three key components of a data processing pipeline for gait analysis. \n",
    "Each section of the notebook is dedicated to a specific part of the process:\n",
    "\n",
    "1. **Data Extraction**: Extracting and initial processing of gait data from a source file.\n",
    "2. **Data Smoothing**: Applying smoothing techniques to the extracted data for better analysis.\n",
    "3. **Leg Movement Analysis**: Analyzing leg movements from the smoothed data to understand gait patterns.\n",
    "\n",
    "The notebook is structured to sequentially execute these steps, ensuring a streamlined workflow from raw data to analysis results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354c7c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Required Libraries\n",
    "%pip install pandas\n",
    "%pip install numpypip install matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ea11f7",
   "metadata": {},
   "source": [
    "# Data Extraction\n",
    "This section focuses on extracting gait data from a given source file. It involves loading the data, initial processing, and preparing it for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75c3d5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gait Data Head:\n",
      "   Time (s)  Forward Acceleration (cm/s^2)  Roll (deg)\n",
      "0 -1.086594                            -24    1.059973\n",
      "1 -1.076598                            -24    1.045649\n",
      "2 -1.066603                            -22    1.045649\n",
      "3 -1.056607                             -9    1.045649\n",
      "4 -1.046612                              0    1.059973\n",
      "Second Data Head:\n",
      "   -1.08659375  -24  1.05997281631276  Unnamed: 3  Toe-Off-Left  \\\n",
      "0    -1.076598  -24          1.045649         NaN        22.637   \n",
      "1    -1.066603  -22          1.045649         NaN        23.843   \n",
      "2    -1.056607   -9          1.045649         NaN        25.049   \n",
      "3    -1.046612    0          1.059973         NaN        35.133   \n",
      "4    -1.036617    3          1.059973         NaN        36.209   \n",
      "\n",
      "   Heal-Down-Left  COM-Above-Heal-Left  COM-Above-Toe-Left  Unnamed: 8  \\\n",
      "0          23.050               23.367              23.542         NaN   \n",
      "1          24.256               24.540              24.773         NaN   \n",
      "2          25.428               25.741              25.937         NaN   \n",
      "3          35.521               35.771              35.938         NaN   \n",
      "4          36.618               36.927              37.098         NaN   \n",
      "\n",
      "   Toe-Off-Right  Heal-Down-Right  COM-Above-Heal-Right  COM-Above-Toe-Right  \n",
      "0         15.716           16.129                16.454               16.642  \n",
      "1         16.967           17.372                17.627               17.864  \n",
      "2         18.207           18.586                18.990               19.095  \n",
      "3         29.117           29.492                29.801               29.947  \n",
      "4         30.203           30.660                30.936               31.115  \n",
      "\n",
      "\n",
      "Left Side Data Head:\n",
      "   Toe-Off-Left  Heal-Down-Left  COM-Above-Heal-Left  COM-Above-Toe-Left\n",
      "0        22.637          23.050               23.367              23.542\n",
      "1        23.843          24.256               24.540              24.773\n",
      "2        25.049          25.428               25.741              25.937\n",
      "3        35.133          35.521               35.771              35.938\n",
      "4        36.209          36.618               36.927              37.098\n",
      "\n",
      "\n",
      "Right Side Data Head:\n",
      "   Toe-Off-Right  Heal-Down-Right  COM-Above-Heal-Right  COM-Above-Toe-Right\n",
      "0         15.716           16.129                16.454               16.642\n",
      "1         16.967           17.372                17.627               17.864\n",
      "2         18.207           18.586                18.990               19.095\n",
      "3         29.117           29.492                29.801               29.947\n",
      "4         30.203           30.660                30.936               31.115\n",
      "\n",
      "Gait Data Head:\n",
      "   Time (s)  Forward Acceleration (cm/s^2)  Roll (deg)\n",
      "0 -1.086594                            -24    1.059973\n",
      "1 -1.076598                            -24    1.045649\n",
      "2 -1.066603                            -22    1.045649\n",
      "3 -1.056607                             -9    1.045649\n",
      "4 -1.046612                              0    1.059973\n",
      "Second Data Head:\n",
      "   -1.08659375  -24  1.05997281631276  Unnamed: 3  Toe-Off-Left  \\\n",
      "0    -1.076598  -24          1.045649         NaN        22.637   \n",
      "1    -1.066603  -22          1.045649         NaN        23.843   \n",
      "2    -1.056607   -9          1.045649         NaN        25.049   \n",
      "3    -1.046612    0          1.059973         NaN        35.133   \n",
      "4    -1.036617    3          1.059973         NaN        36.209   \n",
      "\n",
      "   Heal-Down-Left  COM-Above-Heal-Left  COM-Above-Toe-Left  Unnamed: 8  \\\n",
      "0          23.050               23.367              23.542         NaN   \n",
      "1          24.256               24.540              24.773         NaN   \n",
      "2          25.428               25.741              25.937         NaN   \n",
      "3          35.521               35.771              35.938         NaN   \n",
      "4          36.618               36.927              37.098         NaN   \n",
      "\n",
      "   Toe-Off-Right  Heal-Down-Right  COM-Above-Heal-Right  COM-Above-Toe-Right  \n",
      "0         15.716           16.129                16.454               16.642  \n",
      "1         16.967           17.372                17.627               17.864  \n",
      "2         18.207           18.586                18.990               19.095  \n",
      "3         29.117           29.492                29.801               29.947  \n",
      "4         30.203           30.660                30.936               31.115  \n",
      "\n",
      "\n",
      "Left Side Data Head:\n",
      "   Toe-Off-Left  Heal-Down-Left  COM-Above-Heal-Left  COM-Above-Toe-Left\n",
      "0        22.637          23.050               23.367              23.542\n",
      "1        23.843          24.256               24.540              24.773\n",
      "2        25.049          25.428               25.741              25.937\n",
      "3        35.133          35.521               35.771              35.938\n",
      "4        36.209          36.618               36.927              37.098\n",
      "\n",
      "\n",
      "Right Side Data Head:\n",
      "   Toe-Off-Right  Heal-Down-Right  COM-Above-Heal-Right  COM-Above-Toe-Right\n",
      "0         15.716           16.129                16.454               16.642\n",
      "1         16.967           17.372                17.627               17.864\n",
      "2         18.207           18.586                18.990               19.095\n",
      "3         29.117           29.492                29.801               29.947\n",
      "4         30.203           30.660                30.936               31.115\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ExtractData:\n",
    "    def __init__(self, file_name: str):\n",
    "        \"\"\"\n",
    "        Initialize the ExtractData class with the specified file name.\n",
    "\n",
    "        Args:\n",
    "        file_name (str): The name of the file containing the gait analysis data.\n",
    "        \"\"\"\n",
    "        self.file_name = file_name\n",
    "        self.gait_data = None\n",
    "        self.gait_data_df = None\n",
    "        self.left_side_df = None\n",
    "        self.right_side_df = None\n",
    "        self.filtered_data = None\n",
    "        self.time_ranges = None\n",
    "\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Use CSV file to create different dataframes, and print their contents.\n",
    "        The column names for the Left and Right sides are assumed to be on the second row.\n",
    "        \"\"\"\n",
    "\n",
    "        # Load the Excel file\n",
    "        self.gait_data = pd.read_excel(self.file_name)\n",
    "\n",
    "        # Creating the dataframe with the first three columns\n",
    "        self.gait_data_df = self.gait_data.iloc[:, :3]\n",
    "        print(\"\\nGait Data Head:\")\n",
    "        print(self.gait_data_df.head())  # Display the first few rows of gait_data_df\n",
    "\n",
    "        # Load the entire dataset, setting the second row as header\n",
    "        self.gait_data = pd.read_excel(self.file_name, header=1)\n",
    "        print(\"Second Data Head:\")\n",
    "        print(self.gait_data.head())  # Display the first few rows\n",
    "\n",
    "        # Drop the first four columns from the gait_data\n",
    "        self.gait_data = self.gait_data.iloc[:, 4:]\n",
    "\n",
    "        # Collect the first four columns in self.left_side_df\n",
    "        self.left_side_df = self.gait_data.iloc[:, :4].copy()\n",
    "\n",
    "        # Drop rows with NaN values\n",
    "        self.left_side_df.dropna(inplace=True)\n",
    "        print(\"\\n\\nLeft Side Data Head:\")\n",
    "        print(self.left_side_df.head())  # Display the first few rows of left_side_df\n",
    "\n",
    "        # Drop the first five columns from the gait_data (total drop is now nine columns)\n",
    "        self.gait_data = self.gait_data.iloc[:, 5:]\n",
    "\n",
    "        # Collect the first four columns in self.right_side_df\n",
    "        self.right_side_df = self.gait_data.iloc[:, :4].copy()\n",
    "\n",
    "        # Drop rows with NaN values\n",
    "        self.right_side_df.dropna(inplace=True)\n",
    "        print(\"\\n\\nRight Side Data Head:\")\n",
    "        print(self.right_side_df.head())  # Display the first few rows of right_side_df\n",
    "\n",
    "        # Load the entire dataset, setting the first row as header\n",
    "        self.gait_data = pd.read_excel(self.file_name, header=0)\n",
    "        # print(\"Final Data Head:\")\n",
    "        # print(self.gait_data.head())  # Display the first few rows\n",
    "\n",
    "\n",
    "    def filter_data(self):\n",
    "        \"\"\"\n",
    "        Filter the data based on time ranges.\n",
    "        \"\"\"\n",
    "        # Initialize an empty DataFrame for filtered data\n",
    "        self.filtered_data = pd.DataFrame()\n",
    "\n",
    "        # Loop through each time range in self.time_ranges\n",
    "        for start, end in self.time_ranges:\n",
    "            # Apply the filter for the current time range\n",
    "            current_filtered = self.gait_data_df[(self.gait_data_df['Time (s)'] >= start) & (self.gait_data_df['Time (s)'] <= end)]\n",
    "\n",
    "            # Combine the filtered data from the current time range with the previous ones\n",
    "            self.filtered_data = pd.concat([self.filtered_data, current_filtered])\n",
    "\n",
    "    def plot_roll(self, filtered_data: pd.DataFrame, filename: str):\n",
    "        \"\"\"\n",
    "        Plot the data and save the plot to a file.\n",
    "\n",
    "        Args:\n",
    "        filtered_data (pd.DataFrame): The DataFrame containing the data to be plotted.\n",
    "        filename (str): The name of the file to save the plot, including .png extension.\n",
    "        \"\"\"\n",
    "        # Create a new figure with specific size\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        # Plotting the 'Roll' against 'Time'\n",
    "        plt.plot(filtered_data['Time (s)'], filtered_data['Roll (deg)'], label='Roll')\n",
    "\n",
    "        # Setting the title of the plot\n",
    "        plt.title('Roll vs Time')\n",
    "\n",
    "        # Setting labels for x and y axes\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Roll (degrees)')\n",
    "\n",
    "        # Enabling grid for better readability\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Displaying the legend\n",
    "        plt.legend()\n",
    "\n",
    "        # Saving the plot to a file in PNG format\n",
    "        plt.savefig(filename)\n",
    "\n",
    "        # Closing the plot to free up memory\n",
    "        plt.close()\n",
    "\n",
    "    def plot_acceleration(self, filtered_data: pd.DataFrame, filename: str):\n",
    "        \"\"\"\n",
    "        Plot the data and save the plot to a file.\n",
    "\n",
    "        Args:\n",
    "        filtered_data (pd.DataFrame): The DataFrame containing the data to be plotted.\n",
    "        filename (str): The name of the file to save the plot, including .png extension.\n",
    "        \"\"\"\n",
    "        # Create a new figure with specific size\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        # Plotting the 'Forward Acceleration' against 'Time'\n",
    "        plt.plot(filtered_data['Time (s)'], filtered_data['Forward Acceleration (cm/s^2)'], label='Forward Acceleration')\n",
    "\n",
    "        # Setting the title of the plot\n",
    "        plt.title('Forward Acceleration vs Time')\n",
    "\n",
    "        # Setting labels for x and y axes\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Forward Acceleration (cm/s^2)')\n",
    "\n",
    "        # Enabling grid for better readability\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Displaying the legend\n",
    "        plt.legend()\n",
    "\n",
    "        # Saving the plot to a file in PNG format\n",
    "        plt.savefig(filename)\n",
    "\n",
    "        # Closing the plot to free up memory\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    def save_data(self, filtered_data: pd.DataFrame, filename: str):\n",
    "        \"\"\"\n",
    "        Save the filtered data to a file.\n",
    "\n",
    "        Args:\n",
    "        filtered_data (pd.DataFrame): The DataFrame containing the data to be saved.\n",
    "        filename (str): The name of the file to save the data, including file extension.\n",
    "        \"\"\"\n",
    "        # Saving the DataFrame to a file\n",
    "        filtered_data.to_csv(filename, index=False)\n",
    "\n",
    "\n",
    "    def exec(self) -> tuple[pd.DataFrame, pd.Series]:\n",
    "        \"\"\"\n",
    "        Execute the data extraction and processing flow and return the filtered data and missing data info.\n",
    "\n",
    "        Returns:\n",
    "        tuple: Contains the filtered data as a DataFrame and missing data information as a Series.\n",
    "        \"\"\"\n",
    "        # self.add_labels()\n",
    "        self.load_data()\n",
    "        self.time_ranges = [(15, 19), (22, 26), (29, 32), (35, 38)]\n",
    "        self.filter_data()\n",
    "        self.plot_acceleration(self.filtered_data, 'filtered_acceleration.png')\n",
    "        self.save_data(self.filtered_data, 'filtered_acceleration.csv')\n",
    "\n",
    "        # self.add_labels()\n",
    "        self.load_data()\n",
    "        self.time_ranges = [(15.5, 19), (22.5, 26.5), (29, 33), (35, 39)]\n",
    "        self.filter_data()\n",
    "        self.plot_roll(self.filtered_data, 'filtered_roll.png')\n",
    "        self.save_data(self.filtered_data, 'filtered_roll.csv')\n",
    "\n",
    "# Example usage\n",
    "extractor = ExtractData('Gait_Analysis_Example.xlsx')\n",
    "extractor.exec()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaca9f62",
   "metadata": {},
   "source": [
    "# Data Smoothing\n",
    "In this section, the extracted data is smoothed using statistical methods. This is a crucial step to reduce noise and improve the reliability of the gait data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dfd643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter\n",
    "import numpy as np\n",
    "\n",
    "class SmoothData:\n",
    "    def __init__(self, input_file_path: str, output_file_path: str):\n",
    "        \"\"\"\n",
    "        Initialize the SmoothData class with input and output file paths.\n",
    "\n",
    "        Args:\n",
    "            input_file_path (str): The path to the CSV file containing the data to be processed.\n",
    "            output_file_path (str): The path where the processed (smoothed) data will be saved.\n",
    "        \"\"\"\n",
    "        self.input_file_path = input_file_path\n",
    "        self.output_file_path = output_file_path\n",
    "        self.filtered_data = None\n",
    "        self.smoothed_data = None\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Load the data from the CSV file specified in the input_file_path attribute.\n",
    "        The data is stored in the filtered_data attribute and the first few rows are printed.\n",
    "        \"\"\"\n",
    "        self.filtered_data = pd.read_csv(self.input_file_path)\n",
    "        print(self.filtered_data.head())\n",
    "\n",
    "\n",
    "    def plot_data(self):\n",
    "        \"\"\"\n",
    "        Plot the original and smoothed acceleration data.\n",
    "        The plot is saved to a file named 'smoothed_data_plot.png' and then closed.\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        # plt.plot(self.filtered_data['Time (s)'], self.filtered_data['Forward Acceleration (cm/s^2)'], label='Original Acceleration')\n",
    "        plt.plot(self.filtered_data['Time (s)'], self.filtered_data['Smoothed Acceleration'], label='Smoothed Acceleration', color='red')\n",
    "\n",
    "        # Determine the range for vertical lines\n",
    "        time_min = np.floor(min(self.filtered_data['Time (s)']))\n",
    "        time_max = np.ceil(max(self.filtered_data['Time (s)']))\n",
    "        \n",
    "        # Add vertical lines at every whole number\n",
    "        for x in np.arange(time_min, time_max + 1):\n",
    "            plt.axvline(x, color='grey', linestyle='--', linewidth=0.5)\n",
    "\n",
    "        # Determine the range for horizontal lines\n",
    "        accel_min = np.floor(min(self.filtered_data['Smoothed Acceleration']) / 20) * 20\n",
    "        accel_max = np.ceil(max(self.filtered_data['Smoothed Acceleration']) / 20) * 20\n",
    "\n",
    "        # Add horizontal lines at every multiple of 20\n",
    "        for y in np.arange(accel_min, accel_max + 20, 20):\n",
    "            plt.axhline(y, color='grey', linestyle='--', linewidth=0.5)\n",
    "\n",
    "        plt.title('Original vs. Smoothed Acceleration Data')\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Acceleration (cm/s^2)')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig('smoothed_data_plot.png')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    def exec(self):\n",
    "        \"\"\"\n",
    "        Execute the main workflow of the SmoothData class.\n",
    "        This method loads the data using load_data, smooths it, generates a plot of the data,\n",
    "        and then saves the smoothed data to the output_file_path.\n",
    "        \"\"\"\n",
    "        self.load_data()\n",
    "\n",
    "        # Check if data is loaded\n",
    "        if self.filtered_data is None:\n",
    "            print(\"Data not loaded. Please check the input file path.\")\n",
    "            return\n",
    "\n",
    "        # Smoothing the data\n",
    "        self.filtered_data['Smoothed Acceleration'] = savgol_filter(\n",
    "            self.filtered_data['Forward Acceleration (cm/s^2)'], window_length=51, polyorder=3\n",
    "        )\n",
    "\n",
    "        # Plotting the data\n",
    "        self.plot_data()\n",
    "\n",
    "        # Making a copy of the smoothed data and saving it\n",
    "        self.smoothed_data = self.filtered_data.copy()\n",
    "        self.smoothed_data.to_csv(self.output_file_path, index=False)\n",
    "\n",
    "# Usage\n",
    "input_file_path = 'filtered.csv'\n",
    "output_file_path = 'smoothed.csv'\n",
    "smooth_data = SmoothData(input_file_path, output_file_path)\n",
    "smooth_data.exec()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class DetectEntries:\n",
    "    def __init__(self, file_path: str):\n",
    "        \"\"\"\n",
    "        Initialize the DetectEntries object by reading data from the given CSV file.\n",
    "        \n",
    "        Args:\n",
    "        file_path (str): Path to the CSV file.\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(file_path)\n",
    "        self.initialize_columns()\n",
    "\n",
    "    def initialize_columns(self):\n",
    "        \"\"\"Initialize 'Braking' and 'Propulsion' columns with zeros.\"\"\"\n",
    "        self.data['Braking'] = 0\n",
    "        self.data['Propulsion'] = 0\n",
    "\n",
    "    def detect_entries(self):\n",
    "        \"\"\"\n",
    "        Detect entries for 'Braking' and 'Propulsion' in the dataset.\n",
    "        'Braking' is set when transitioning from above zero to zero or less.\n",
    "        'Propulsion' is set when transitioning from below zero to zero or more.\n",
    "        \"\"\"\n",
    "        for i in range(1, len(self.data)):\n",
    "            if self.data['Smoothed Acceleration'].iloc[i-1] > 0 and self.data['Smoothed Acceleration'].iloc[i] <= 0:\n",
    "                self.data.at[i, 'Braking'] = 1  # Using .at[] for label-based indexing\n",
    "            if self.data['Smoothed Acceleration'].iloc[i-1] < 0 and self.data['Smoothed Acceleration'].iloc[i] >= 0:\n",
    "                self.data.at[i, 'Propulsion'] = 1  # Using .at[] for label-based indexing\n",
    "\n",
    "    def plot_data(self):\n",
    "        \"\"\"Plot the 'Braking' and 'Propulsion' data over time.\"\"\"\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        braking_times = self.data['Time (s)'][self.data['Braking'] == 1]\n",
    "        plt.scatter(braking_times, [1] * len(braking_times), marker='|', color='r', label='Braking', s=100)\n",
    "        propulsion_times = self.data['Time (s)'][self.data['Propulsion'] == 1]\n",
    "        plt.scatter(propulsion_times, [1] * len(propulsion_times), marker='+', color='b', label='Propulsion', s=100)\n",
    "        plt.title('Braking and Propulsion Over Time (s)')\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Indicator')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    def save_data(self, file_path: str):\n",
    "        \"\"\"\n",
    "        Save the modified data to a new CSV file.\n",
    "        \n",
    "        Args:\n",
    "        file_path (str): Path to the CSV file where the data will be saved.\n",
    "        \"\"\"\n",
    "        self.data.to_csv(file_path, index=False)\n",
    "\n",
    "    def exec(self):\n",
    "        \"\"\"\n",
    "        Execute the methods to detect entries, plot data, and save the data.\n",
    "        \"\"\"\n",
    "        self.detect_entries()\n",
    "        self.plot_data()\n",
    "        self.save_data('entry_data.csv')\n",
    "\n",
    "# Example of how to use the class\n",
    "output_file_path = 'smoothed.csv'\n",
    "detect_entries = DetectEntries(output_file_path)\n",
    "detect_entries.exec()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29c6ccb",
   "metadata": {},
   "source": [
    "# Leg Movement Analysis\n",
    "The final section analyzes leg movements using the smoothed gait data. It aims to identify patterns and anomalies in gait, which are essential for understanding movement dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d948ee7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class Leg:\n",
    "    \"\"\"\n",
    "    A class to analyze leg stance phases from roll angle data.\n",
    "\n",
    "    Attributes:\n",
    "        file_path (str): The path to the CSV file containing the data.\n",
    "        data (pd.DataFrame): The loaded data from the CSV file.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, file_path: str):\n",
    "        \"\"\"\n",
    "        Initialize the Leg class with the file path of the data.\n",
    "        \"\"\"\n",
    "        self.file_path = file_path\n",
    "        self.data = None\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Load data from the CSV file into a pandas DataFrame.\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(self.file_path)\n",
    "\n",
    "    def detect_batches(self, time_column: str, gap_threshold: float = 1):\n",
    "        \"\"\"\n",
    "        Detect batches in the data based on a specified time gap threshold.\n",
    "\n",
    "        Args:\n",
    "            time_column (str): The column name in the DataFrame that contains time data.\n",
    "            gap_threshold (float): The threshold in time units to detect a new batch.\n",
    "        \"\"\"\n",
    "        time_diff = self.data[time_column].diff()\n",
    "        batch_indices = time_diff > gap_threshold\n",
    "        self.data['Batch'] = np.cumsum(batch_indices).fillna(0)\n",
    "\n",
    "    def mark_leg_in_segments(self, roll_column: str):\n",
    "        \"\"\"\n",
    "        Mark which leg the subject is standing on during different segments.\n",
    "\n",
    "        Args:\n",
    "            roll_column (str): The column name in the DataFrame that contains roll angle data.\n",
    "        \"\"\"\n",
    "        # Initialize and compute the required columns\n",
    "        self.data['Leg'] = ''\n",
    "        self.data['Roll_diff'] = self.data[roll_column].diff()\n",
    "\n",
    "        # Process each batch separately\n",
    "        for batch in self.data['Batch'].unique():\n",
    "            batch_data = self.data[self.data['Batch'] == batch]\n",
    "\n",
    "            # Identify right and left leg stance segments\n",
    "            self._process_leg_segments(batch_data, roll_column)\n",
    "\n",
    "    def _process_leg_segments(self, batch_data: pd.DataFrame, roll_column: str):\n",
    "        \"\"\"\n",
    "        Helper method to process leg segments within a batch of data.\n",
    "\n",
    "        Args:\n",
    "            batch_data (pd.DataFrame): The data for the current batch.\n",
    "            roll_column (str): The column name for roll angle data.\n",
    "        \"\"\"\n",
    "        # Right Foot Down Segments\n",
    "        right_start_indices = batch_data[(batch_data['Roll_diff'].shift(-1) > 0) & \n",
    "                                         (batch_data['Roll_diff'] <= 0) & \n",
    "                                         (batch_data[roll_column] < -1.5)].index\n",
    "        for start_idx in right_start_indices:\n",
    "            end_idx = batch_data.loc[start_idx:][batch_data['Roll (deg)'] >= 0].first_valid_index()\n",
    "            if end_idx is not None:\n",
    "                self.data.loc[start_idx:end_idx, 'Leg'] = 'Right'\n",
    "\n",
    "        # Left Foot Down Segments\n",
    "        left_start_indices = batch_data[(batch_data['Roll_diff'].shift(-1) <= 0) & \n",
    "                                        (batch_data['Roll_diff'] > 0) & \n",
    "                                        (batch_data[roll_column] > 2.5)].index\n",
    "        for start_idx in left_start_indices:\n",
    "            end_idx = batch_data.loc[start_idx:][batch_data['Roll (deg)'] <= 0].first_valid_index()\n",
    "            if end_idx is not None:\n",
    "                self.data.loc[start_idx:end_idx, 'Leg'] = 'Left'\n",
    "\n",
    "    def plot_data(self):\n",
    "        \"\"\"\n",
    "        Plot the roll angle data with colors indicating the stance leg.\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        # Plot each data point\n",
    "        for index, row in self.data.iterrows():\n",
    "            color = 'red' if row['Leg'] == 'Right' else 'black' if row['Leg'] == 'Left' else 'yellow'\n",
    "            plt.scatter(row['Time (s)'], row['Roll (deg)'], color=color, s=5)\n",
    "\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Roll (deg)')\n",
    "        plt.title('Roll Angle Over Time with Leg Stance Phases')\n",
    "        plt.savefig('leg.png')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    def calculate_max_deviation(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Calculate the maximum angular roll deviation for each contiguous set of rows\n",
    "        during single leg stance phases.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame containing the max deviation data for each stance segment.\n",
    "        \"\"\"\n",
    "        max_deviation_data = []\n",
    "\n",
    "        # Iterate through each batch\n",
    "        for batch in self.data['Batch'].unique():\n",
    "            batch_data = self.data[self.data['Batch'] == batch]\n",
    "\n",
    "            # Process for each leg\n",
    "            for leg in ['Right', 'Left']:\n",
    "                leg_data = batch_data[batch_data['Leg'] == leg]\n",
    "\n",
    "                # Find contiguous segments within the leg data\n",
    "                # A segment changes when there is a break in the index sequence\n",
    "                segments = leg_data['Roll (deg)'].groupby((leg_data.index.to_series().diff() != 1).cumsum())\n",
    "\n",
    "                # Calculate max deviation for each segment\n",
    "                for segment_num, segment_data in segments:\n",
    "                    if not segment_data.empty:\n",
    "                        time_start = segment_data.index.min()\n",
    "                        time_end = segment_data.index.max()\n",
    "                        max_deviation = segment_data.abs().max()\n",
    "\n",
    "                        # Append this information to the max_deviation_data list\n",
    "                        max_deviation_data.append({\n",
    "                            'Batch': batch, \n",
    "                            'Leg': leg, \n",
    "                            'Segment': segment_num,\n",
    "                            'Time Start': self.data.loc[time_start, 'Time (s)'],\n",
    "                            'Time End': self.data.loc[time_end, 'Time (s)'],\n",
    "                            'Max Deviation': max_deviation\n",
    "                        })\n",
    "\n",
    "        return pd.DataFrame(max_deviation_data)\n",
    "\n",
    "    def save_data(self, output_file_path: str):\n",
    "        \"\"\"\n",
    "        Save the modified data to a CSV file.\n",
    "\n",
    "        Args:\n",
    "            output_file_path (str): Path to save the output CSV file.\n",
    "        \"\"\"\n",
    "        self.data.to_csv(output_file_path, index=False)\n",
    "\n",
    "    def exec(self):\n",
    "        \"\"\"\n",
    "        Execute the entire process of data loading, processing, plotting, and saving.\n",
    "        \"\"\"\n",
    "        self.load_data()\n",
    "        self.detect_batches('Time (s)')\n",
    "        self.mark_leg_in_segments('Roll (deg)')\n",
    "        self.plot_data()\n",
    "        max_deviation_df = self.calculate_max_deviation()\n",
    "        max_deviation_df.to_csv('max_deviation_data.csv', index=False)\n",
    "\n",
    "# Usage\n",
    "leg = Leg('filtered_roll.csv')\n",
    "leg.exec()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "homework",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
